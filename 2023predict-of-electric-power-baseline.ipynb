{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data manipulation\n",
        "includes importing the data and feature engineering"
      ],
      "metadata": {
        "id": "82Ta13bpPaWe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-10-03T14:30:04.545342Z",
          "iopub.status.busy": "2023-10-03T14:30:04.544551Z",
          "iopub.status.idle": "2023-10-03T14:30:04.550390Z",
          "shell.execute_reply": "2023-10-03T14:30:04.549132Z",
          "shell.execute_reply.started": "2023-10-03T14:30:04.545302Z"
        },
        "id": "us9UYG1E1MZv",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#Library for importing csv files\n",
        "import pandas as pd\n",
        "#Library for matrix operations\n",
        "import numpy as np\n",
        "#Set random seeds to ensure that the model can be reproduced\n",
        "import random\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## importing training data and test data"
      ],
      "metadata": {
        "id": "q1NofqdGQGC5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-10-03T14:30:04.556580Z",
          "iopub.status.busy": "2023-10-03T14:30:04.555843Z",
          "iopub.status.idle": "2023-10-03T14:30:05.017935Z",
          "shell.execute_reply": "2023-10-03T14:30:05.016306Z",
          "shell.execute_reply.started": "2023-10-03T14:30:04.556545Z"
        },
        "id": "olNTK4Ep1MZx",
        "outputId": "068545ef-06f5-41b5-d6c7-5322256ebb00",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "len(train_df):263160\n",
            "len(test_df):17136\n"
          ]
        }
      ],
      "source": [
        "# importing data which is in .csv format\n",
        "train_df=pd.read_csv(\"train_df.csv\")\n",
        "print(f\"len(train_df):{len(train_df)}\")\n",
        "test_df=pd.read_csv(\"test_df.csv\")\n",
        "print(f\"len(test_df):{len(test_df)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# concatinating the training and test data frames for futher data manipulation\n",
        "total_df=pd.concat((train_df,test_df),axis=0)\n",
        "# dropping f1 and f2 columns in the dataset since it is not informative\n",
        "total_df.drop([\"f1\",\"f2\"], axis=1,inplace= True)"
      ],
      "metadata": {
        "id": "S4VAcBpKQrie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-Oq8qXaU3M8",
        "outputId": "86ddcc24-06ef-4bc0-e524-340a88e6ad9b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 280296 entries, 0 to 17135\n",
            "Data columns (total 8 columns):\n",
            " #   Column        Non-Null Count   Dtype  \n",
            "---  ------        --------------   -----  \n",
            " 0   id            280296 non-null  int64  \n",
            " 1   id_encode     280295 non-null  float64\n",
            " 2   hour          280295 non-null  float64\n",
            " 3   parking_free  280295 non-null  float64\n",
            " 4   year          280295 non-null  float64\n",
            " 5   month         280295 non-null  float64\n",
            " 6   day           280295 non-null  float64\n",
            " 7   power         263159 non-null  float64\n",
            "dtypes: float64(7), int64(1)\n",
            "memory usage: 19.2 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#forward_fill: Missing values ​​are filled according to the previous value\n",
        "total_df.fillna(method='ffill', inplace=True)\n",
        "total_df['ds']=pd.to_datetime(total_df[['year','month','day','hour']])\n",
        "total_df[\"Day sin\"] = np.sin(total_df[\"day\"]*(2*np.pi / 30))\n",
        "total_df[\"Day cos\"] = np.cos(total_df[\"day\"]*(2*np.pi / 30))\n",
        "total_df['sin month']=np.sin(2*np.pi*total_df['month']/12)\n",
        "total_df['cos month']=np.cos(2*np.pi*total_df['month']/12)\n",
        "total_df['sin_hour']=np.sin(2*np.pi*total_df['hour']/24)\n",
        "total_df['cos_hour']=np.cos(2*np.pi*total_df['hour']/24)\n",
        "total_df.drop(columns= [\"day\", \"month\",\"hour\"], axis=1, inplace=True)"
      ],
      "metadata": {
        "id": "mkL5NuUDVH_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "total_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xwM13c1LcxYG",
        "outputId": "08ba9590-f4fd-4620-d379-f1e3b80fb8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 280296 entries, 0 to 17135\n",
            "Data columns (total 12 columns):\n",
            " #   Column        Non-Null Count   Dtype         \n",
            "---  ------        --------------   -----         \n",
            " 0   id            280296 non-null  int64         \n",
            " 1   id_encode     280296 non-null  float64       \n",
            " 2   parking_free  280296 non-null  float64       \n",
            " 3   year          280296 non-null  float64       \n",
            " 4   power         280296 non-null  float64       \n",
            " 5   ds            280296 non-null  datetime64[ns]\n",
            " 6   Day sin       280296 non-null  float64       \n",
            " 7   Day cos       280296 non-null  float64       \n",
            " 8   sin month     280296 non-null  float64       \n",
            " 9   cos month     280296 non-null  float64       \n",
            " 10  sin_hour      280296 non-null  float64       \n",
            " 11  cos_hour      280296 non-null  float64       \n",
            "dtypes: datetime64[ns](1), float64(10), int64(1)\n",
            "memory usage: 27.8 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_df.drop(columns=[\"id\", \"year\", \"ds\", \"parking_free\"], inplace= True)\n",
        "total_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6QyLnGHefIDZ",
        "outputId": "5ef99b5c-5b13-49de-9f2b-a1f37206212a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 280296 entries, 0 to 17135\n",
            "Data columns (total 8 columns):\n",
            " #   Column     Non-Null Count   Dtype  \n",
            "---  ------     --------------   -----  \n",
            " 0   id_encode  280296 non-null  float64\n",
            " 1   power      280296 non-null  float64\n",
            " 2   Day sin    280296 non-null  float64\n",
            " 3   Day cos    280296 non-null  float64\n",
            " 4   sin month  280296 non-null  float64\n",
            " 5   cos month  280296 non-null  float64\n",
            " 6   sin_hour   280296 non-null  float64\n",
            " 7   cos_hour   280296 non-null  float64\n",
            "dtypes: float64(8)\n",
            "memory usage: 19.2 MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## normalizing the power column\n",
        "Normalizing using the Standard Deviation Normalization method"
      ],
      "metadata": {
        "id": "7QU807vphf2E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_df[\"power\"] = (total_df[\"power\"] - total_df[\"power\"].mean()) / total_df[\"power\"].std()"
      ],
      "metadata": {
        "id": "zVGRekT8fuqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-03T14:30:05.063945Z",
          "iopub.status.busy": "2023-10-03T14:30:05.063169Z",
          "iopub.status.idle": "2023-10-03T14:30:24.362806Z",
          "shell.execute_reply": "2023-10-03T14:30:24.361796Z",
          "shell.execute_reply.started": "2023-10-03T14:30:05.063911Z"
        },
        "id": "aCxOffsM1MZy",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# total_df['up_of_month']=(total_df['day']<=10)\n",
        "# total_df['down_of_month']=(total_df['day']>20)\n",
        "# total_df['morning']=(total_df['hour']>5)&(total_df['hour']<=12)\n",
        "# total_df['afternoon']=(total_df['hour']>12)&(total_df['hour']<=19)\n",
        "# total_df['evening']=1-total_df['morning']-total_df['afternoon']\n",
        "\n",
        "# total_df['ds']=pd.to_datetime(total_df[['year','month','day','hour']])\n",
        "# total_df['weekday']=total_df['ds'].dt.weekday\n",
        "# total_df['sin_week']=np.sin(2*np.pi*total_df['weekday']/7)\n",
        "# total_df['cos_week']=np.cos(2*np.pi*total_df['weekday']/7)\n",
        "# total_df['is_friday']=(total_df['weekday']==4)\n",
        "# total_df['is_weekend']=(total_df['weekday']==5)|(total_df['weekday']==6)\n",
        "# total_df['day_of_year']=total_df['ds'].dt.dayofyear\n",
        "\n",
        "# #GetChina's holidays\n",
        "# # holiday = holidays.China()\n",
        "# # total_df['ds']=pd.to_datetime(total_df[['year','month','day','hour']])\n",
        "# # ds=total_df['ds'].values\n",
        "# # is_holiday = [0 if holiday.get(pd.to_datetime(ds[i]))==\"None\" else 1 for i in range(len(ds))]\n",
        "# # total_df['is_holiday']=is_holiday\n",
        "\n",
        "# total_df['sin_hour']=np.sin(2*np.pi*total_df['hour']/24)\n",
        "# total_df['cos_hour']=np.cos(2*np.pi*total_df['hour']/24)\n",
        "\n",
        "\n",
        "# total_df.drop(['ds'],axis=1,inplace=True)\n",
        "# total_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-10-03T14:30:24.365519Z",
          "iopub.status.busy": "2023-10-03T14:30:24.365127Z",
          "iopub.status.idle": "2023-10-03T14:30:28.710011Z",
          "shell.execute_reply": "2023-10-03T14:30:28.708922Z",
          "shell.execute_reply.started": "2023-10-03T14:30:24.365487Z"
        },
        "id": "7rJfoecF1MZz",
        "outputId": "56a4735c-650b-4600-f8ab-48c503cfa43b",
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "total_feature_counts:87\n"
          ]
        }
      ],
      "source": [
        "# train_df=total_df[:len(train_df)]\n",
        "# keys=train_df.keys()\n",
        "# for key in keys:\n",
        "#     values=np.unique(train_df[key].values)#Get the value of each column\n",
        "\n",
        "#     if len(values)<=500 and key!=\"power\":\n",
        "#         #print(f\"key:{key},values:{values}\")\n",
        "#         key_target=train_df['power'].groupby([train_df[key]]).mean()\n",
        "#         keys=key_target.keys().values\n",
        "#         target=key_target.values\n",
        "#         key_target=pd.DataFrame({key:keys,key+\"_target_mean\":target})\n",
        "#         total_df=pd.merge(total_df,key_target,on=key,how=\"left\")\n",
        "#         key_target=train_df['power'].groupby([train_df[key]]).std()\n",
        "#         keys=key_target.keys().values\n",
        "#         target=key_target.values\n",
        "#         key_target=pd.DataFrame({key:keys,key+\"_target_std\":target})\n",
        "#         total_df=pd.merge(total_df,key_target,on=key,how=\"left\")\n",
        "\n",
        "# #Extract all data according to 25% and 75%, low and high will be out_of_memory\n",
        "# train_df=total_df[:len(train_df)]\n",
        "# test_df=total_df[len(train_df):]\n",
        "# del total_df\n",
        "# print(f\"total_feature_counts:{len(train_df.keys().values)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and test Data Frames\n",
        "extracing test_df and train_df from our total_df with new features"
      ],
      "metadata": {
        "id": "d3_cIGcjiRMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "main_df=total_df[:len(train_df)]\n",
        "prediction_df=total_df[len(train_df):]\n",
        "\n",
        "print(f\"train set length : {len(train_df)}\\ntest set length: {len(test_df)}\")"
      ],
      "metadata": {
        "id": "ln1389R_iuuC",
        "outputId": "b85f9416-a5f1-4278-f4ad-e7b42462259b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set length : 263160\n",
            "test set length: 17136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradient Boosting Ensemble Method\n",
        "using LGBMRegressor for predictions"
      ],
      "metadata": {
        "id": "XQFzfMIXkqfN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-03T14:30:28.711927Z",
          "iopub.status.busy": "2023-10-03T14:30:28.711493Z",
          "iopub.status.idle": "2023-10-03T14:30:30.529421Z",
          "shell.execute_reply": "2023-10-03T14:30:30.528233Z",
          "shell.execute_reply.started": "2023-10-03T14:30:28.711895Z"
        },
        "id": "yXd_B6oW1MZ0",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import KFold #Import the k-fold cross validation function in the machine learning library\n",
        "from lightgbm import LGBMRegressor #Import the integrated learning algorithm lightgbm\n",
        "def RMSE(y_true,y_pred):\n",
        "    return np.sqrt(np.mean((y_true-y_pred)**2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "execution": {
          "iopub.execute_input": "2023-10-03T14:30:30.531562Z",
          "iopub.status.busy": "2023-10-03T14:30:30.531196Z",
          "iopub.status.idle": "2023-10-03T14:53:34.219508Z",
          "shell.execute_reply": "2023-10-03T14:53:34.218379Z",
          "shell.execute_reply.started": "2023-10-03T14:30:30.531533Z"
        },
        "id": "z3f7ONYQ1MZ0",
        "outputId": "d9de85e4-0c86-4a26-f590-5a830dfc3cd1",
        "trusted": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start fit.\n",
            "train_RMSE:[0.3328398889321753],valid_RMSE:[0.38481594119123297]\n",
            "train_RMSE:[0.3328398889321753, 0.33367642737094366],valid_RMSE:[0.38481594119123297, 0.3898513985594672]\n",
            "train_RMSE:[0.3328398889321753, 0.33367642737094366, 0.33302245799146707],valid_RMSE:[0.38481594119123297, 0.3898513985594672, 0.3907355080851898]\n",
            "train_RMSE:[0.3328398889321753, 0.33367642737094366, 0.33302245799146707, 0.33389790831093474],valid_RMSE:[0.38481594119123297, 0.3898513985594672, 0.3907355080851898, 0.3749267257585107]\n",
            "train_RMSE:[0.3328398889321753, 0.33367642737094366, 0.33302245799146707, 0.33389790831093474, 0.33345142203302525],valid_RMSE:[0.38481594119123297, 0.3898513985594672, 0.3907355080851898, 0.3749267257585107, 0.3795972329863007]\n",
            "train_RMSE:[0.3328398889321753, 0.33367642737094366, 0.33302245799146707, 0.33389790831093474, 0.33345142203302525, 0.33245138884184333],valid_RMSE:[0.38481594119123297, 0.3898513985594672, 0.3907355080851898, 0.3749267257585107, 0.3795972329863007, 0.38015201466192977]\n",
            "train_RMSE:[0.3328398889321753, 0.33367642737094366, 0.33302245799146707, 0.33389790831093474, 0.33345142203302525, 0.33245138884184333, 0.3334812857949336],valid_RMSE:[0.38481594119123297, 0.3898513985594672, 0.3907355080851898, 0.3749267257585107, 0.3795972329863007, 0.38015201466192977, 0.38216524183706757]\n",
            "train_RMSE:[0.3328398889321753, 0.33367642737094366, 0.33302245799146707, 0.33389790831093474, 0.33345142203302525, 0.33245138884184333, 0.3334812857949336, 0.33279982636390554],valid_RMSE:[0.38481594119123297, 0.3898513985594672, 0.3907355080851898, 0.3749267257585107, 0.3795972329863007, 0.38015201466192977, 0.38216524183706757, 0.39003446366236644]\n",
            "train_RMSE:[0.3328398889321753, 0.33367642737094366, 0.33302245799146707, 0.33389790831093474, 0.33345142203302525, 0.33245138884184333, 0.3334812857949336, 0.33279982636390554, 0.3337892188971873],valid_RMSE:[0.38481594119123297, 0.3898513985594672, 0.3907355080851898, 0.3749267257585107, 0.3795972329863007, 0.38015201466192977, 0.38216524183706757, 0.39003446366236644, 0.3791720886082105]\n",
            "train_RMSE:[0.3328398889321753, 0.33367642737094366, 0.33302245799146707, 0.33389790831093474, 0.33345142203302525, 0.33245138884184333, 0.3334812857949336, 0.33279982636390554, 0.3337892188971873, 0.33276806997509234],valid_RMSE:[0.38481594119123297, 0.3898513985594672, 0.3907355080851898, 0.3749267257585107, 0.3795972329863007, 0.38015201466192977, 0.38216524183706757, 0.39003446366236644, 0.3791720886082105, 0.3896235477788396]\n",
            "mean_train_RMSE:0.3332177894511508\n",
            "mean_valid_RMSE:0.38410741631291156\n"
          ]
        }
      ],
      "source": [
        "print(\"start fit.\")\n",
        "folds = 10 #Divide the data into 10 parts\n",
        "y = main_df['power']\n",
        "X = main_df.drop(['power'],axis=1)\n",
        "\n",
        "train_RMSE=[]\n",
        "valid_RMSE=[]\n",
        "# Store the list of learned models\n",
        "models = []\n",
        "\n",
        "#Shuffle the data set randomly and divide it into folds\n",
        "kf = KFold(n_splits=folds, shuffle=True, random_state=2023)\n",
        "\n",
        "#Divide x_train into a training set and a verification set in a ratio of 9:1, and take out the subscripts\n",
        "for train_index, valid_index in kf.split(X):\n",
        "\n",
        "    #Get the data of the training set and validation set based on the subscripts\n",
        "    x_train_cv = X.iloc[train_index]\n",
        "    y_train_cv = y.iloc[train_index]\n",
        "    x_valid_cv =X.iloc[valid_index]\n",
        "    y_valid_cv = y.iloc[valid_index]\n",
        "\n",
        "    #Call the LightGBM regression model and add parameters\n",
        "    model = LGBMRegressor(colsample_bytree=0.6503468706312049,\n",
        "              learning_rate=0.020010277043886332, max_bin=127,\n",
        "              min_child_samples=8, n_estimators=1001,\n",
        "              early_stopping_rounds = 100, #If the accuracy has not improved after training for 100 times, stop training.\n",
        "              num_leaves=402,reg_alpha=0.01631050699150689,\n",
        "              reg_lambda=0.01300300057057842,verbose=-1)\n",
        "\n",
        "\n",
        "    #Use x_train_cv to train the model, and use x_train_cv and x_valid_cv to evaluate together\n",
        "    model.fit(\n",
        "        x_train_cv,\n",
        "        y_train_cv,\n",
        "        eval_set = [(x_train_cv, y_train_cv), (x_valid_cv, y_valid_cv)],\n",
        "        #verbose = 100, #Iterate 100 times and output a result\n",
        "    )\n",
        "\n",
        "    #Predict the training set\n",
        "    y_pred_train = model.predict(x_train_cv, num_iteration=model.best_iteration_)\n",
        "    #Predict on the validation set\n",
        "    y_pred_valid = model.predict(x_valid_cv, num_iteration=model.best_iteration_)\n",
        "\n",
        "    train_rmse=RMSE(y_pred_train,y_train_cv)\n",
        "    valid_rmse=RMSE(y_pred_valid,y_valid_cv)\n",
        "\n",
        "    train_RMSE.append(train_rmse)\n",
        "    valid_RMSE.append(valid_rmse)\n",
        "    #Save model into list\n",
        "    models.append(model)\n",
        "    print(f\"train_RMSE:{train_RMSE},valid_RMSE:{valid_RMSE}\")\n",
        "\n",
        "train_RMSE=np.array(train_RMSE)\n",
        "valid_RMSE=np.array(valid_RMSE)\n",
        "\n",
        "print(f\"mean_train_RMSE:{np.mean(train_RMSE)}\")\n",
        "print(f\"mean_valid_RMSE:{np.mean(valid_RMSE)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-03T14:53:34.223277Z",
          "iopub.status.busy": "2023-10-03T14:53:34.220831Z",
          "iopub.status.idle": "2023-10-03T14:53:42.156365Z",
          "shell.execute_reply": "2023-10-03T14:53:42.155235Z",
          "shell.execute_reply.started": "2023-10-03T14:53:34.223230Z"
        },
        "id": "BgFmECi01MZ1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "test_X = test_df.drop(['power'],axis=1).values\n",
        "#Use each saved model to predict x_test once, and then take the average\n",
        "preds_test = []\n",
        "\n",
        "for model in models:\n",
        "\n",
        "    pred = model.predict(test_X, num_iteration=model.best_iteration_)\n",
        "\n",
        "    preds_test.append(pred)\n",
        "\n",
        "#Convert the prediction results into np.array\n",
        "preds_test_np = np.array(preds_test)\n",
        "#Average the prediction results of each model by column\n",
        "test_pred= preds_test_np.mean(axis=0)\n",
        "test_pred=np.where(test_pred<=0,0,test_pred)\n",
        "test_pred[:50]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-03T14:53:42.158252Z",
          "iopub.status.busy": "2023-10-03T14:53:42.157836Z",
          "iopub.status.idle": "2023-10-03T14:53:42.230039Z",
          "shell.execute_reply": "2023-10-03T14:53:42.228945Z",
          "shell.execute_reply.started": "2023-10-03T14:53:42.158214Z"
        },
        "id": "1-Art-s01MZ1",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "submission=pd.read_csv(\"sample_submission.csv\")\n",
        "submission['power']=test_pred\n",
        "submission.to_csv(\"baseline.csv\",index=None)\n",
        "submission.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network model\n",
        "Using a Multi Layer model for predection"
      ],
      "metadata": {
        "id": "J_KLcDGBqXG1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66Ot1pELDl8v",
        "outputId": "8105adcc-1de2-4a6e-c3bb-b66fa635b422",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f0dd832cbb0>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "torch.manual_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and Test split"
      ],
      "metadata": {
        "id": "GUK4_QKNQsgi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_test_ratio = 0.8\n",
        "train_dataset = main_df[ : int(len(train_df)*train_test_ratio)]\n",
        "test_dataset = main_df[int(len(train_df)*train_test_ratio) : ]"
      ],
      "metadata": {
        "id": "5Xn7NQgrQxS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wEwxZLgHwxR"
      },
      "outputs": [],
      "source": [
        "X_train_tensor = torch.Tensor(train_dataset.drop(['power'],axis=1).values.astype(np.float32))\n",
        "y_train_tensor = torch.Tensor(train_dataset['power'].values.astype(np.float32))\n",
        "\n",
        "X_test_tensor = torch.Tensor(test_dataset.drop(['power'],axis=1).values.astype(np.float32))\n",
        "y_test_tensor = torch.Tensor(test_dataset['power'].values.astype(np.float32))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_tensor.shape , y_train_tensor.shape"
      ],
      "metadata": {
        "id": "vYSBua84R2De",
        "outputId": "ef531dd2-06d9-44e1-d3da-d0e4f8cd0372",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([210528, 7]), torch.Size([210528]))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbDd2kcyJTGU"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dgKSPZGYJck3"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "device = \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiJHj_nZJhrs"
      },
      "outputs": [],
      "source": [
        "class RegressionModel(nn.Module):\n",
        "    def __init__(self, input_features, hidden_units, output_size):\n",
        "        super().__init__()\n",
        "        self.linear_layer_stack = nn.Sequential(\n",
        "            nn.Linear(in_features=input_features, out_features=hidden_units),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=hidden_units, out_features=4),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(in_features=4, out_features=output_size),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear_layer_stack(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uWtI_sbiKb-o"
      },
      "outputs": [],
      "source": [
        "nn_model = RegressionModel(input_features= X_train_tensor.shape[1],\n",
        "                    output_size=1,\n",
        "                    hidden_units= 8).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9AQS2hVqLdTo"
      },
      "outputs": [],
      "source": [
        "criterion = nn.MSELoss()  # Mean Squared Error for regression\n",
        "optimizer = optim.AdamW(nn_model.parameters(), lr=0.02)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jR8o-42S5cI",
        "outputId": "04eed6f2-5f90-4ee5-9bc2-ce9e50d3e0ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "output shape =  torch.Size([128, 1])\n",
            "targets shape =  torch.Size([128, 1])\n",
            "loss value =  1.1553386449813843\n"
          ]
        }
      ],
      "source": [
        "## try a single run on the model to check the output shapes\n",
        "nn_model.train()\n",
        "for inputs, targets in train_loader:\n",
        "    output = nn_model(inputs)\n",
        "    print(\"output shape = \", output.shape)\n",
        "    targets = targets.unsqueeze(dim=1)\n",
        "    print(\"targets shape = \", targets.shape)\n",
        "    loss = criterion(output, targets)\n",
        "    print(\"loss value = \", loss.item())\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xkkD3aYMCFC",
        "outputId": "22de5250-f9f0-4755-b0aa-9cab699d4d05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0\n",
            "-------\n",
            "\n",
            "Train loss: 0.79628 | Test loss: 0.98649\n",
            "Epoch: 1\n",
            "-------\n",
            "\n",
            "Train loss: 0.75656 | Test loss: 1.03925\n",
            "Epoch: 2\n",
            "-------\n",
            "\n",
            "Train loss: 0.74396 | Test loss: 1.05232\n",
            "Epoch: 3\n",
            "-------\n",
            "\n",
            "Train loss: 0.73867 | Test loss: 1.13611\n",
            "Epoch: 4\n",
            "-------\n",
            "\n",
            "Train loss: 0.73675 | Test loss: 1.07861\n",
            "Epoch: 5\n",
            "-------\n",
            "\n",
            "Train loss: 0.73654 | Test loss: 1.07169\n",
            "Epoch: 6\n",
            "-------\n",
            "\n",
            "Train loss: 0.73681 | Test loss: 1.16946\n",
            "Epoch: 7\n",
            "-------\n",
            "\n",
            "Train loss: 0.73753 | Test loss: 1.05498\n",
            "Epoch: 8\n",
            "-------\n",
            "\n",
            "Train loss: 0.73740 | Test loss: 1.14926\n",
            "Epoch: 9\n",
            "-------\n",
            "\n",
            "Train loss: 0.73784 | Test loss: 1.04795\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  print(f\"Epoch: {epoch}\\n-------\")\n",
        "\n",
        "  nn_model.train()\n",
        "  ### Training\n",
        "  train_loss = 0\n",
        "  for batch, (inputs, targets) in enumerate(train_loader):\n",
        "    targets = targets.unsqueeze(dim=1)\n",
        "    # 1. Forward pass\n",
        "    outputs = nn_model(inputs)\n",
        "    # 2. Calculate loss (per batch)\n",
        "    loss = torch.sqrt(criterion(outputs, targets))\n",
        "    train_loss += loss # accumulatively add up the loss per epoch\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "    #if batch % 400 == 0:\n",
        "      #print(f\"Looked at {batch * len(inputs)}/{len(train_loader.dataset)} samples\")\n",
        "\n",
        "  # Divide total train loss by length of train dataloader (average loss per batch per epoch)\n",
        "  train_loss /= len(train_loader)\n",
        "  ### Testing\n",
        "  # Setup variables for accumulatively adding up loss and accuracy\n",
        "  test_loss = 0\n",
        "  nn_model.eval()\n",
        "  with torch.inference_mode():\n",
        "    rmse_sum = 0.0\n",
        "    num_samples = 0\n",
        "    for inputs, targets in test_loader:\n",
        "      targets = targets.unsqueeze(dim=1)\n",
        "      # 1. Forward pass\n",
        "      test_outputs = nn_model(inputs)\n",
        "      # 2. Calculate loss (accumatively)\n",
        "      test_loss += torch.sqrt(criterion(test_outputs, targets))\n",
        "\n",
        "    # Divide total test loss by length of test dataloader (per epoch)\n",
        "    test_loss /= len(test_loader)\n",
        "  ## Print out what's happening\n",
        "  print(f\"\\nTrain loss: {train_loss:.5f} | Test loss: {test_loss:.5f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}